{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8ee6c9d-4190-4c4c-9481-d4e292ff6560",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Neural Network on MBA Admission Dataset**\n",
    "\n",
    "## **Overview**\n",
    "In this notebook, we will apply the Neural Network algorithm to predict the admission status of MBA applicants based on various features like gender, GPA, GMAT score, work experience, and more. We will also evaluate the performance of the model using key classification metrics such as Accuracy, Precision, Recall, and F1-score, and visualize the structure of the Neural Network\n",
    "\n",
    "### **Dataset**\n",
    "The dataset contains information on MBA applicants, including:\n",
    "- **Gender**: Gender of the applicant\n",
    "- **International**: Whether the applicant is an international student\n",
    "- **GPA**: Grade point average\n",
    "- **Major**: Undergraduate major\n",
    "- **Race**: Race/ethnicity of the applicant\n",
    "- **GMAT**: GMAT score of the applicant\n",
    "- **Work Experience**: Number of years of work experience\n",
    "- **Work Industry**: The industry where the applicant works\n",
    "- **Admission**: Whether the applicant was admitted (Target Variable)\n",
    "\n",
    "### **Objective**\n",
    "Our goal is to use a Neural Network to predict whether an applicant will be admitted based on the available features, while also visualizing the tree to understand how the model makes decisions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ff7fd6-002b-4f3c-844d-2ea48d172dc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('MBA.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4cc6a3-fe2c-4df6-a6d1-97945a92871c",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "## Data Preprocessing\n",
    "\n",
    "The data will be processed in a similar manner to the KNN example, including handling missing values, encoding categorical variables, and splitting the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188f184b-3526-4777-895d-cb0132f8ceca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data['race']=data['race'].fillna('International')\n",
    "data['admission']=data['admission'].fillna('Deny')\n",
    "data.isna().sum()\n",
    "\n",
    "data[\"admission\"].value_counts()\n",
    "# Dropping all rows where the 'admission' column is 'Waitlist'\n",
    "data = data[data['admission'] != 'Waitlist']\n",
    "\n",
    "# Verifying that the 'Waitlist' rows are dropped\n",
    "data['admission'].value_counts()\n",
    "\n",
    "# Encode categorical variables\n",
    "data['gender'] = data['gender'].map({'Male': 0, 'Female': 1})\n",
    "data['international'] = data['international'].astype(int)\n",
    "data['admission'] = data['admission'].map({'Admit': 1, 'Deny': 0})\n",
    "\n",
    "# One-hot encode categorical columns like 'major', 'race', and 'work_industry'\n",
    "data = pd.get_dummies(data, columns=['major', 'race', 'work_industry'], drop_first=True)\n",
    "\n",
    "# Display the processed dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd55d94-26a2-465f-8aa3-9a9bb5476161",
   "metadata": {},
   "source": [
    "\n",
    "### Splitting the Data\n",
    "We split the dataset into training and testing sets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a8233a-117a-4211-aab8-e54b02d347f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the data into features (X) and target (y)\n",
    "X = data.drop('admission', axis=1)\n",
    "y = data['admission']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both the training and test sets\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71347800-c721-4250-b98e-9d16ea7d3ce9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ü§ñ **Understanding Neural Networks with the MBA Admission Dataset**\n",
    "\n",
    "## **Overview:**\n",
    "In this document, we will explore how neural networks work using the MBA Admission dataset. After preprocessing the data, we will:\n",
    "1. Train a Multi-Layer Perceptron (MLP) model to predict whether an MBA applicant is admitted.\n",
    "2. Understand the important parameters of MLP and how they affect model performance.\n",
    "3. Evaluate model performance using classification metrics like Accuracy, Precision, Recall, and F1-Score.\n",
    "4. Dive deeper into how **hidden layers** and **activation functions** contribute to the model's learning ability.\n",
    "\n",
    "---\n",
    "\n",
    "## **üóÉÔ∏è Dataset Description:**\n",
    "The MBA Admission dataset contains features such as academic scores, work experience, and other relevant metrics that help determine whether an applicant is admitted to the MBA program. The target variable is **'Admitted'**, which indicates if the applicant was admitted or not.\n",
    "\n",
    "---\n",
    "\n",
    "## **üîÑ Preprocessing the Data:**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## **ü§ñ How Neural Networks Work:**\n",
    "\n",
    "Multi-Layer Perceptrons (MLP) are a type of feedforward neural network, composed of an input layer, one or more hidden layers, and an output layer. Here‚Äôs how they work:\n",
    "\n",
    "### 1. **Layers and Neurons**:\n",
    "   - **Input Layer**: Receives input data (features) and passes it to the next layer.\n",
    "   - **Hidden Layers**: Contain neurons that learn features from the input data. The number of neurons and layers determines the model's capacity to learn complex patterns.\n",
    "   - **Output Layer**: Provides the final output, which, in this case, is a binary prediction (admitted or not).\n",
    "\n",
    "### 2. **Activation Functions**:\n",
    "   - Activation functions introduce **non-linearity** into the model, allowing it to learn complex relationships. Common activation functions include **ReLU** (Rectified Linear Unit) and **sigmoid**.\n",
    "\n",
    "### 3. **Training and Backpropagation**:\n",
    "   - **Forward Pass**: The input data passes through the network, and predictions are generated.\n",
    "   - **Loss Calculation**: A loss function (e.g., **cross-entropy**) calculates the error between predicted and actual values.\n",
    "   - **Backpropagation**: The model adjusts the weights by minimizing the loss using an optimization algorithm (e.g., **stochastic gradient descent**).\n",
    "\n",
    "### 4. **Reduce Overfitting**\n",
    "   - **Regularization (`alpha`)**: Tune `alpha` for L2 regularization to penalize large weights.\n",
    "   - **Reduce Model Complexity**: Adjust model depth and neuron counts to control complexity.\n",
    "   - **Cross-Validation**: Apply cross-validation to find optimal parameters (like `hidden_layer_sizes` and `alpha`).\n",
    "\n",
    "---\n",
    "\n",
    "## **üìâ Plotting Training vs. Testing Curves**\n",
    "\n",
    "To assess the model‚Äôs learning dynamics and detect overfitting or underfitting, we plot the training and testing loss curves over multiple epochs:\n",
    "- **Training Curve**: Tracks the model‚Äôs performance on the training data.\n",
    "- **Testing Curve**: Shows how well the model generalizes to unseen data.\n",
    "\n",
    "This plot helps identify points where overfitting may begin.\n",
    "\n",
    "---\n",
    "\n",
    "## **üîç Interpreting with SHAP**\n",
    "\n",
    "### **What are SHAP Values?**\n",
    "SHAP (SHapley Additive exPlanations) values help interpret the contribution of each feature in the model's prediction. SHAP values indicate how much each feature pushes a prediction higher or lower compared to the average prediction.\n",
    "\n",
    "### **Using SHAP with Our Model**\n",
    "1. **SHAP Summary Plot**: Shows feature importance by displaying the average SHAP value of each feature.\n",
    "2. **SHAP Force Plot**: Visualizes individual predictions, highlighting the positive or negative contribution of each feature.\n",
    "3. **SHAP Dependence Plot**: Examines the effect of individual features in the context of interactions with other features.\n",
    "\n",
    "---\n",
    "\n",
    "## **üìä Evaluation Metrics**\n",
    "\n",
    "To evaluate the model, we use:\n",
    "- **Mean Absolute Error (MAE)**: Measures the average magnitude of errors in predictions.\n",
    "- **Mean Squared Error (MSE)**: Penalizes larger errors, useful for gauging prediction accuracy.\n",
    "- **R-squared (R¬≤)**: Indicates the proportion of variance explained by the model.\n",
    "\n",
    "---\n",
    "\n",
    "## **üéØ Summary and Insights**\n",
    "By combining scaling, overfitting reduction, visualizations, and SHAP values, we gain a comprehensive understanding of the model‚Äôs performance and feature importance. This project not only predicts housing prices but also sheds light on the impact of each feature, making it useful for practical insights into real estate valuation. üè°üíº"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c1f740-053a-49b3-9714-daf125aa933a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, learning_curve\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Define the MLPClassifier\n",
    "\n",
    "def our_mlp(mlp, num_epochs):\n",
    "    \n",
    "    # Prepare lists to track the loss\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        # Train with partial fit (incremental learning)\n",
    "        mlp.partial_fit(X_train, y_train, classes=np.unique(y_train))\n",
    "\n",
    "        # Calculate training loss\n",
    "        train_loss = log_loss(y_train, mlp.predict_proba(X_train))\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Calculate test loss\n",
    "        test_loss = log_loss(y_test, mlp.predict_proba(X_test))\n",
    "        test_losses.append(test_loss)\n",
    "        if epoch % 50 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} - Training Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}\")\n",
    "    return (train_losses, test_losses)\n",
    "    \n",
    "def plot_mlp(train_losses, test_losses):\n",
    "    # Plot the training and test loss curves\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, len(train_losses) + 1), train_losses, '-', color='r', label='Training loss')\n",
    "    plt.plot(range(1, len(test_losses) + 1), test_losses, '-', color='g', label='Test loss')\n",
    "    plt.title('Training and Test Loss Curves (MLPClassifier)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Log Loss')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dca6276-a135-4539-8030-d0603bec0f81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(50, 30), warm_start=True, random_state=42)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c273d135-95f7-4e9c-93c0-e209ba58459c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(50, 30), max_iter=1, warm_start=True, random_state=42)\n",
    "(train_losses, test_losses) = our_mlp(mlp, 300)\n",
    "plot_mlp(train_losses, test_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01689986-a9ef-4bcd-ae1a-d1febb441867",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Explanation\n",
    "- **Hidden Layers**: We define two hidden layers with 50 and 30 neurons, respectively. More neurons and layers can increase the model's ability to learn but may also lead to overfitting.\n",
    "- **Max Iterations**: Controls how many times the model will iterate to optimize weights.\n",
    "- **Activation Function**: The default activation function is **ReLU** for hidden layers, allowing the model to handle non-linearity in data.\n",
    "\n",
    "---\n",
    "\n",
    "## **üìä Evaluating Model Performance:**\n",
    "\n",
    "To evaluate the MLP model, we use several metrics:\n",
    "\n",
    "1. **Accuracy**: Measures the overall correctness of predictions.\n",
    "2. **Classification Report**: Provides **precision**, **recall**, and **F1-score** for each class, offering a detailed view of model performance.\n",
    "3. **Confusion Matrix**: Shows the counts of **true positives**, **true negatives**, **false positives**, and **false negatives**, helping us understand where the model makes mistakes.\n",
    "\n",
    "---\n",
    "\n",
    "## **üí° Insights on Neural Network Performance:**\n",
    "\n",
    "- **Hidden Layer Size**: Adding more neurons or layers can improve performance but may also require more computational resources and may lead to overfitting if not properly regularized.\n",
    "- **Scaling**: Neural networks are sensitive to input scale, hence scaling is crucial for effective training.\n",
    "\n",
    "In this document, we explored how neural networks can be applied to predict MBA admissions. We went through data preprocessing, model training, and performance evaluation, offering insights into how MLP parameters affect model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21b5a0f-1ff8-49e6-9ec0-1c2715f02708",
   "metadata": {
    "tags": []
   },
   "source": [
    "# üåü Reducing Overfitting in MLPClassifier: A Comprehensive Guide\n",
    "\n",
    "When training an `MLPClassifier`, overfitting can hinder performance on unseen data. This guide explores various strategies to mitigate overfitting effectively. Let's dive into each method and make your model robust and generalizable! üéâ \n",
    "\n",
    "---\n",
    "\n",
    "## üõ†Ô∏è 1. Regularization with `alpha`\n",
    "\n",
    "- **What It Does**: The `alpha` parameter controls L2 regularization, which penalizes large weights, reducing model complexity.\n",
    "- **How to Use It**:\n",
    "  ```python\n",
    "\n",
    "  ```\n",
    "- **Pro Tip**: Start with a small `alpha` (e.g., 0.0001) and increase it gradually. Too high an `alpha` can lead to underfitting. üéõÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c92cae-7250-4d4f-ae97-98d708f3b6b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(50, 30), max_iter=1000, alpha=0.0001, random_state=42)\n",
    "(train_losses, test_losses) = our_mlp(mlp, 300)\n",
    "plot_mlp(train_losses, test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f976501-03ea-4ed1-afb2-b34cd3d0aafd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(50, 30), max_iter=1000, alpha=0.1, random_state=42)\n",
    "(train_losses, test_losses) = our_mlp(mlp, 300)\n",
    "plot_mlp(train_losses, test_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bc8f41-1cbc-48d1-8f2c-dd1bc7f3e532",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## üîç 2. Reduce Model Complexity\n",
    "\n",
    "- **Why**: Smaller networks have fewer parameters, making it harder for the model to memorize the training data.\n",
    "- **Example**:\n",
    "  ```python\n",
    "  mlp = MLPClassifier(hidden_layer_sizes=(30,), max_iter=300, random_state=42)\n",
    "  ```\n",
    "- **Configurations to Try**: Test hidden layer sizes like `(50,)`, `(30, 20)`, or `(50, 50)`. Finding the balance is key! ‚öñÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb00fa3e-d534-42b3-b8e5-1a06d4eb06e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(10), max_iter=1000, alpha=0.1, random_state=42)\n",
    "(train_losses, test_losses) = our_mlp(mlp, 300)\n",
    "plot_mlp(train_losses, test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca430100-83b0-48fa-8e62-09b7dc6ebca2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(20), max_iter=1000, alpha=0.1, random_state=42)\n",
    "(train_losses, test_losses) = our_mlp(mlp, 1000)\n",
    "plot_mlp(train_losses, test_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb23c95-d61b-4651-b7f2-2f497069979f",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "# üåü Understanding SHAP Values: A Quick Guide\n",
    "\n",
    "SHAP (SHapley Additive exPlanations) values are a powerful tool to interpret machine learning models. They help us see how much each feature contributes to a specific prediction, making even complex models more understandable.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ú® Key Concepts\n",
    "\n",
    "- **SHAP Value**: Measures each feature's contribution to a prediction.\n",
    "  - **Positive SHAP value** ‚û°Ô∏è The feature pushes the prediction higher.\n",
    "  - **Negative SHAP value** ‚û°Ô∏è The feature pushes the prediction lower.\n",
    "\n",
    "### üîç How SHAP Values Work\n",
    "\n",
    "1. **Base Value** üéØ: This is the average prediction of the model across all data points, serving as the starting point for each prediction.\n",
    "2. **Feature Contributions** üìä: SHAP values show how much each feature ‚Äúpushes‚Äù the prediction away from the base value, calculated by considering all possible combinations of features.\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Example\n",
    "\n",
    "Imagine a model predicts a credit score of **0.8** (on a scale of 0 to 1), and the base value is **0.5**:\n",
    "\n",
    "- **Salary** ü§ë with a SHAP value of **0.2** means it **increases** the score by 0.2.\n",
    "- **Debt** üí∏ with a SHAP value of **-0.1** means it **decreases** the score by 0.1.\n",
    "\n",
    "So, the final prediction **0.8** is the base value **0.5** plus the contributions from salary and debt.\n",
    "\n",
    "---\n",
    "\n",
    "### üìù Summary\n",
    "\n",
    "SHAP values let us open the ‚Äúblack box‚Äù of machine learning models, revealing how each feature influences the outcome. They provide transparency and insight, helping you trust and understand your model's predictions.\n",
    "\n",
    "---\n",
    "\n",
    "With SHAP values, even the most complex models become interpretable, empowering you to make informed decisions with confidence! üéâ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d16badd-396a-48dd-b534-ba97746987c1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# üîé Using SHAP Values for Model Interpretation in MLPClassifier\n",
    "\n",
    "SHAP (SHapley Additive exPlanations) values provide insights into feature contributions to model predictions, which is especially helpful in understanding and refining models trained with scikit-learn's `MLPClassifier`.\n",
    "\n",
    "## Why Use SHAP?\n",
    "- **Feature Importance**: SHAP values help interpret which features are driving the model‚Äôs predictions and can reveal if specific features overly influence the model.\n",
    "- **Overfitting Detection**: If certain features dominate the predictions, it might indicate overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb58339e-125a-463a-b785-5f6c654c6f79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "# Explain the model's predictions using SHAP\n",
    "\n",
    "# Randomly sample 100 instances from the training set for the SHAP background\n",
    "background = shap.sample(X_train, 20)\n",
    "\n",
    "explainer = shap.KernelExplainer(mlp.predict, background, feature_names=X.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b968cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shap_values = explainer(X_test)  # Calculate SHAP values for the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5da226b-093b-4053-9b01-4e5977719e91",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Understanding SHAP Plots for Model Interpretation\n",
    "\n",
    "Using SHAP values provides insights into feature importance and individual predictions. This document explains how to interpret different types of SHAP plots, including summary, force, and dependence plots.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. SHAP Summary Plot (Bar)\n",
    "\n",
    "```python\n",
    "# Summary plot of SHAP values (bar plot for feature importance)\n",
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\")\n",
    "```\n",
    "### What It Shows\n",
    "- **Purpose**: Provides a high-level view of feature importance across the entire dataset.\n",
    "- **Interpretation**: Each bar represents the average absolute SHAP value of a feature, indicating its overall importance in the model.\n",
    "- **Insight**: Longer bars indicate features that have a larger impact on model predictions on average. This is useful for identifying the most influential features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a321d1a6-0d37-4785-999a-e5cdc1053fdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\", feature_names=X.columns)  # Bar plot for feature importance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3e154d-2274-42cb-869d-939308e80994",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## 2. SHAP Summary Plot (Density)\n",
    "\n",
    "```python\n",
    "\n",
    "```\n",
    "### What It Shows\n",
    "- **Purpose**: Displays the distribution of SHAP values for each feature, highlighting how they contribute to different predictions.\n",
    "- **Interpretation**: Each point represents a SHAP value for a feature in a specific instance. Points are color-coded by feature values (e.g., blue for low and red for high).\n",
    "- **Insight**: The spread of SHAP values for each feature shows its influence across various instances. Features with both positive and negative SHAP values indicate they contribute to increasing or decreasing the prediction based on their values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bfe98d-9469-4d54-b862-b60bc3811174",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Detailed SHAP value plot for individual features (traditional summary plot)\n",
    "shap.summary_plot(shap_values, X_test, feature_names=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab41bcc-d03e-4e30-90b6-3dc4a0f2bd9e",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## 3. SHAP Force Plot (Single Prediction)\n",
    "\n",
    "\n",
    "### What It Shows\n",
    "- **Purpose**: Explains a single prediction by showing how each feature value pushes the prediction away from the expected value (baseline).\n",
    "- **Interpretation**: Features that push the prediction higher are shown in red, while those pushing it lower are in blue. The length of each segment represents the strength of the feature‚Äôs impact.\n",
    "- **Insight**: The force plot helps in understanding the main drivers behind a specific prediction. It is particularly useful in identifying key factors that lead to higher or lower model outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f378ecb3-72ac-4025-9ae4-c76b0f7ac464",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Round SHAP values and the expected value to 2 decimals\n",
    "rounded_shap_values = np.round(shap_values[0].values, 2)\n",
    "rounded_expected_value = np.round(explainer.expected_value, 2)\n",
    "\n",
    "# Convert the first instance of X_test to a pandas Series and round values\n",
    "X_test_rounded = pd.Series(X_test[0], index=X.columns).apply(lambda x: f\"{x:.2f}\")\n",
    "\n",
    "# Generate the force plot\n",
    "shap.force_plot(rounded_expected_value, rounded_shap_values, X_test_rounded, \n",
    "                matplotlib=True, feature_names=X.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300f3759-8044-4756-8b99-7e6735433c80",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "# SHAP Force Plot Explanation\n",
    "\n",
    "This document provides a brief explanation of the SHAP force plot and how each feature affects the model's prediction for a single instance.\n",
    "\n",
    "---\n",
    "\n",
    "### Structure of the Plot\n",
    "\n",
    "1. **Base Value**: This is the starting point (or baseline) of the model‚Äôs prediction, which is the average prediction across all training data. In this plot, it is near zero.\n",
    "\n",
    "2. **f(x)**: This represents the final prediction for this specific instance after considering the contributions of each feature. Here, `f(x)` is **-0.01**.\n",
    "\n",
    "3. **Feature Contributions (Arrows)**:\n",
    "   - **Red Arrows**: Features pushing the prediction higher (positive impact on `f(x)`).\n",
    "   - **Blue Arrows**: Features pushing the prediction lower (negative impact on `f(x)`).\n",
    "   - The length of each arrow represents the strength of the feature‚Äôs impact.\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation of Each Feature\n",
    "\n",
    "- **`international = 1.53`**: Positively impacts `f(x)`, pushing it up by about 0.15.\n",
    "- **`gpa = 1.78`**: Has a positive effect, increasing `f(x)` by around 0.10.\n",
    "- **`gender = 1.33`**: Slightly increases `f(x)`, with an impact close to 0.05.\n",
    "- **`application_id = 0.16`**: Has a minor negative effect, decreasing `f(x)` by around 0.02.\n",
    "- **`gmat = -0.84`**: Negatively impacts `f(x)`, lowering it by about 0.10.\n",
    "- **`major_Humanities = -0.82`**: Strongly decreases `f(x)`, with a negative impact of around 0.15.\n",
    "\n",
    "### Summary\n",
    "\n",
    "The model‚Äôs prediction `f(x)` of **-0.01** is the combined result of all these feature effects. Positive contributions from `international`, `gpa`, and `gender` are nearly balanced by the negative contributions from `gmat` and `major_Humanities`, resulting in a neutral prediction.\n",
    "\n",
    "This plot allows us to understand which features have the most influence on this particular prediction and whether their impact is positive or negative.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6c1ad4-88ef-430d-9a13-7801d31bc426",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## 4. SHAP Dependence Plot (for a specific feature)\n",
    "\n",
    "### What It Shows\n",
    "- **Purpose**: Shows the effect of a specific feature on the prediction while considering the impact of other interacting features.\n",
    "- **Interpretation**: The x-axis represents values of the selected feature, and the y-axis shows SHAP values for that feature. Color coding represents another interacting feature, providing context on how interactions affect predictions.\n",
    "- **Insight**: This plot highlights both the individual impact of a feature and any interactions with other features. For example, if 'gmat' score has a high SHAP value at certain levels, the plot can reveal how it influences predictions in the context of other variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd367d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.scatter(shap_values[:, \"gmat\"], color=shap_values[:, \"gender\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68399985",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.scatter(shap_values[:, \"gmat\"], color=shap_values[:, \"race_Black\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e22783a-1bac-4949-bf5c-cc16a6d4f871",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Interactive SHAP dependence plot for a specific feature (e.g., 'gmat' score)\n",
    "shap.dependence_plot('gmat', shap_values.values, X_test, feature_names=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f72e3c-6553-43fd-bfe0-30032b214bc3",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "By combining these SHAP plots, you can gain a comprehensive understanding of your model:\n",
    "- The **bar summary plot** offers a quick look at overall feature importance.\n",
    "- The **density summary plot** provides more detail on feature impact distributions.\n",
    "- The **force plot** explains individual predictions.\n",
    "- The **dependence plot** reveals interactions and the influence of specific features.\n",
    "\n",
    "Using these plots together enables a deep dive into model behavior, helping diagnose potential overfitting, feature dominance, and instance-specific impacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3494b9-a852-4a08-b3cc-ae145f1c7157",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
